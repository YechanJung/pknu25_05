{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "data_dir = os.getenv(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting audio from MP4 file: /Users/jung-yechan/Documents/Research/pknu/MELD.Raw/train/train_splits/dia0_utt3.mp4\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf57.83.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1280, 720], 'bitrate': 660, 'fps': 23.976023976023978, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': 'eng', 'default': True, 'fps': 48000, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 2.75, 'bitrate': 798, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [1280, 720], 'video_bitrate': 660, 'video_fps': 23.976023976023978, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 48000, 'audio_bitrate': 127, 'video_duration': 2.75, 'video_n_frames': 65}\n",
      "/Users/jung-yechan/.pyenv/versions/3.9.20/envs/dl/lib/python3.9/site-packages/imageio_ffmpeg/binaries/ffmpeg-macos-aarch64-v7.1 -i /Users/jung-yechan/Documents/Research/pknu/MELD.Raw/train/train_splits/dia0_utt3.mp4 -loglevel error -f image2pipe -vf scale=1280:720 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "Writing audio to temporary file...\n",
      "Loading noise reduction model...\n",
      "Loading audio from temp_audio.wav...\n",
      "Audio loaded: shape=(121275, 2), sample_rate=44100\n",
      "Converting audio to model format...\n",
      "Processing stereo audio, shape: torch.Size([121275, 2])\n",
      "Audio tensor shape after formatting: torch.Size([1, 1, 121275])\n",
      "Resampling from 44100 Hz to 16000 Hz with 1 channels\n",
      "Applying noise reduction...\n",
      "Enhanced audio shape: (44000,)\n"
     ]
    }
   ],
   "source": [
    "from mp4_noise_reducer import noise_reduce_mp4\n",
    "\n",
    "enhanced, sr = noise_reduce_mp4(data_dir+\"/train/train_splits/dia0_utt3.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.signal  # Missing import\n",
    "\n",
    "def compute_linear_trend(feature_sequence):\n",
    "    \"\"\"\n",
    "    Calculate the slope of the linear trend in a feature sequence.\n",
    "    Positive values indicate rising trend, negative values indicate falling trend.\n",
    "    \n",
    "    Args:\n",
    "        feature_sequence: Array of feature values over time\n",
    "        \n",
    "    Returns:\n",
    "        Slope of the best-fit line\n",
    "    \"\"\"\n",
    "    # Create time indices (normalized to [0,1])\n",
    "    feature_sequence = np.array(feature_sequence)  # Ensure numpy array\n",
    "    n_frames = len(feature_sequence)\n",
    "    \n",
    "    # Handle edge cases\n",
    "    if n_frames < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    # Check if array contains only identical values\n",
    "    if np.all(feature_sequence == feature_sequence[0]):\n",
    "        return 0.0\n",
    "    \n",
    "    time_indices = np.linspace(0, 1, n_frames)\n",
    "    \n",
    "    # Compute linear regression\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(\n",
    "        time_indices, feature_sequence\n",
    "    )\n",
    "    \n",
    "    # Normalize by feature range to handle different scales\n",
    "    feature_range = np.max(feature_sequence) - np.min(feature_sequence)\n",
    "    if feature_range > 0:\n",
    "        normalized_slope = slope / feature_range\n",
    "    else:\n",
    "        normalized_slope = 0.0\n",
    "    \n",
    "    return normalized_slope\n",
    "\n",
    "def compute_feature_dynamism(feature_sequence):\n",
    "    \"\"\"\n",
    "    Calculate the dynamism (variability in rate of change) of a feature.\n",
    "    Higher values indicate more dynamic expression.\n",
    "    \n",
    "    Args:\n",
    "        feature_sequence: Array of feature values over time\n",
    "        \n",
    "    Returns:\n",
    "        Dynamism score\n",
    "    \"\"\"\n",
    "    feature_sequence = np.array(feature_sequence)  # Ensure numpy array\n",
    "    \n",
    "    # Handle edge cases\n",
    "    if len(feature_sequence) < 3:  # Need at least 3 points for second derivative\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute first derivative (rate of change)\n",
    "    first_derivative = np.diff(feature_sequence)\n",
    "    \n",
    "    # Compute second derivative (acceleration)\n",
    "    second_derivative = np.diff(first_derivative)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    first_derivative_mean = np.mean(np.abs(first_derivative))\n",
    "    first_derivative_std = np.std(first_derivative)\n",
    "    second_derivative_mean = np.mean(np.abs(second_derivative))\n",
    "    \n",
    "    # Combine into dynamism measure (normalized to feature range)\n",
    "    feature_range = np.max(feature_sequence) - np.min(feature_sequence)\n",
    "    if feature_range > 0:\n",
    "        dynamism = (0.5 * first_derivative_std + \n",
    "                   0.3 * first_derivative_mean + \n",
    "                   0.2 * second_derivative_mean) / feature_range\n",
    "    else:\n",
    "        dynamism = 0.0\n",
    "    \n",
    "    return dynamism\n",
    "\n",
    "def detect_bursts(feature_sequence, threshold=1.5, min_duration=3):\n",
    "    \"\"\"\n",
    "    Detect burst patterns in a feature sequence.\n",
    "    \n",
    "    Args:\n",
    "        feature_sequence: Array of feature values over time\n",
    "        threshold: Threshold for burst detection (multiplier over local mean)\n",
    "        min_duration: Minimum frames to be considered a burst\n",
    "        \n",
    "    Returns:\n",
    "        List of (start_index, end_index, magnitude) for each burst\n",
    "    \"\"\"\n",
    "    feature_sequence = np.array(feature_sequence)  # Ensure numpy array\n",
    "    \n",
    "    # Handle empty array\n",
    "    if len(feature_sequence) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Normalize feature sequence\n",
    "    feature_mean = np.mean(feature_sequence)\n",
    "    feature_std = np.std(feature_sequence)\n",
    "    if feature_std > 0:\n",
    "        normalized_sequence = (feature_sequence - feature_mean) / feature_std\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    # Detect regions above threshold\n",
    "    above_threshold = normalized_sequence > threshold\n",
    "    \n",
    "    # Find continuous regions (bursts)\n",
    "    bursts = []\n",
    "    in_burst = False\n",
    "    burst_start = 0\n",
    "    \n",
    "    for i, is_above in enumerate(above_threshold):\n",
    "        if is_above and not in_burst:\n",
    "            # Start of new burst\n",
    "            in_burst = True\n",
    "            burst_start = i\n",
    "        elif not is_above and in_burst:\n",
    "            # End of burst\n",
    "            burst_end = i\n",
    "            burst_duration = burst_end - burst_start\n",
    "            \n",
    "            if burst_duration >= min_duration:\n",
    "                # Calculate burst magnitude\n",
    "                burst_magnitude = np.mean(normalized_sequence[burst_start:burst_end])\n",
    "                bursts.append((burst_start, burst_end, burst_magnitude))\n",
    "            \n",
    "            in_burst = False\n",
    "    \n",
    "    # Handle case where sequence ends during a burst\n",
    "    if in_burst:\n",
    "        burst_end = len(above_threshold)\n",
    "        burst_duration = burst_end - burst_start\n",
    "        \n",
    "        if burst_duration >= min_duration:\n",
    "            burst_magnitude = np.mean(normalized_sequence[burst_start:burst_end])\n",
    "            bursts.append((burst_start, burst_end, burst_magnitude))\n",
    "    \n",
    "    return bursts\n",
    "\n",
    "def compute_burst_features(feature_sequence, threshold=1.5, min_duration=3):\n",
    "    \"\"\"\n",
    "    Compute features based on burst patterns.\n",
    "    \n",
    "    Args:\n",
    "        feature_sequence: Array of feature values over time\n",
    "        threshold: Threshold for burst detection\n",
    "        min_duration: Minimum frames for a burst\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of burst-related features\n",
    "    \"\"\"\n",
    "    feature_sequence = np.array(feature_sequence)  # Ensure numpy array\n",
    "    \n",
    "    bursts = detect_bursts(feature_sequence, threshold, min_duration)\n",
    "    \n",
    "    n_frames = len(feature_sequence)\n",
    "    if n_frames == 0:\n",
    "        return {\n",
    "            'burst_count': 0,\n",
    "            'burst_rate': 0,\n",
    "            'mean_burst_magnitude': 0,\n",
    "            'max_burst_magnitude': 0,\n",
    "            'burst_coverage': 0,\n",
    "            'first_burst_position': 0\n",
    "        }\n",
    "    \n",
    "    # Compute burst features\n",
    "    burst_count = len(bursts)\n",
    "    burst_rate = burst_count / n_frames\n",
    "    \n",
    "    if burst_count > 0:\n",
    "        burst_magnitudes = [b[2] for b in bursts]\n",
    "        burst_durations = [b[1] - b[0] for b in bursts]\n",
    "        total_burst_frames = sum(burst_durations)\n",
    "        \n",
    "        mean_burst_magnitude = np.mean(burst_magnitudes)\n",
    "        max_burst_magnitude = np.max(burst_magnitudes)\n",
    "        burst_coverage = total_burst_frames / n_frames\n",
    "        first_burst_position = bursts[0][0] / n_frames if bursts else 0\n",
    "    else:\n",
    "        mean_burst_magnitude = 0\n",
    "        max_burst_magnitude = 0\n",
    "        burst_coverage = 0\n",
    "        first_burst_position = 0\n",
    "    \n",
    "    return {\n",
    "        'burst_count': burst_count,\n",
    "        'burst_rate': burst_rate,\n",
    "        'mean_burst_magnitude': mean_burst_magnitude,\n",
    "        'max_burst_magnitude': max_burst_magnitude,\n",
    "        'burst_coverage': burst_coverage,\n",
    "        'first_burst_position': first_burst_position\n",
    "    }\n",
    "\n",
    "def analyze_peaks(feature_sequence, distance=5, prominence=0.1, width=None):\n",
    "    \"\"\"\n",
    "    Perform comprehensive peak analysis on a feature sequence.\n",
    "    \n",
    "    Args:\n",
    "        feature_sequence: Array of feature values over time\n",
    "        distance: Minimum samples between peaks\n",
    "        prominence: Minimum peak prominence\n",
    "        width: Minimum peak width\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of peak-related features\n",
    "    \"\"\"\n",
    "    feature_sequence = np.array(feature_sequence)  # Ensure numpy array\n",
    "    \n",
    "    # Handle empty array\n",
    "    n_frames = len(feature_sequence)\n",
    "    if n_frames == 0:\n",
    "        return {\n",
    "            'peak_count': 0,\n",
    "            'peak_rate': 0,\n",
    "            'mean_peak_prominence': 0,\n",
    "            'max_peak_prominence': 0,\n",
    "            'peak_position_mean': 0.5,\n",
    "            'peak_position_std': 0,\n",
    "            'peak_width_mean': 0\n",
    "        }\n",
    "    \n",
    "    # Normalize feature sequence to [0,1]\n",
    "    if np.max(feature_sequence) > np.min(feature_sequence):\n",
    "        normalized = (feature_sequence - np.min(feature_sequence)) / (np.max(feature_sequence) - np.min(feature_sequence))\n",
    "    else:\n",
    "        normalized = np.zeros_like(feature_sequence)\n",
    "    \n",
    "    # Find peaks with try/except to handle potential errors\n",
    "    try:\n",
    "        peaks, properties = scipy.signal.find_peaks(\n",
    "            normalized,\n",
    "            distance=distance,\n",
    "            prominence=prominence,\n",
    "            width=width\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error finding peaks: {e}\")\n",
    "        return {\n",
    "            'peak_count': 0,\n",
    "            'peak_rate': 0,\n",
    "            'mean_peak_prominence': 0,\n",
    "            'max_peak_prominence': 0,\n",
    "            'peak_position_mean': 0.5,\n",
    "            'peak_position_std': 0,\n",
    "            'peak_width_mean': 0\n",
    "        }\n",
    "    \n",
    "    # Compute peak features\n",
    "    peak_count = len(peaks)\n",
    "    peak_rate = peak_count / n_frames\n",
    "    \n",
    "    if peak_count > 0:\n",
    "        # Make sure properties contains all expected keys\n",
    "        peak_prominences = properties.get('prominences', np.zeros(peak_count))\n",
    "        peak_widths = properties.get('widths', np.zeros(peak_count))\n",
    "        peak_positions = peaks / n_frames  # Normalize positions to [0,1]\n",
    "        \n",
    "        mean_peak_prominence = np.mean(peak_prominences)\n",
    "        max_peak_prominence = np.max(peak_prominences) if len(peak_prominences) > 0 else 0\n",
    "        peak_position_mean = np.mean(peak_positions)\n",
    "        peak_position_std = np.std(peak_positions)\n",
    "        peak_width_mean = np.mean(peak_widths) / n_frames if len(peak_widths) > 0 else 0  # Normalize to utterance length\n",
    "    else:\n",
    "        mean_peak_prominence = 0\n",
    "        max_peak_prominence = 0\n",
    "        peak_position_mean = 0.5  # Default to middle\n",
    "        peak_position_std = 0\n",
    "        peak_width_mean = 0\n",
    "    \n",
    "    return {\n",
    "        'peak_count': peak_count,\n",
    "        'peak_rate': peak_rate,\n",
    "        'mean_peak_prominence': mean_peak_prominence,\n",
    "        'max_peak_prominence': max_peak_prominence,\n",
    "        'peak_position_mean': peak_position_mean,\n",
    "        'peak_position_std': peak_position_std,\n",
    "        'peak_width_mean': peak_width_mean\n",
    "    }\n",
    "\n",
    "def extract_energy_envelope(audio_signal, sample_rate=16000, window_size=0.025, window_step=0.010):\n",
    "    \"\"\"\n",
    "    Extract energy envelope from audio signal.\n",
    "    \n",
    "    Args:\n",
    "        audio_signal: Raw audio samples\n",
    "        sample_rate: Sample rate in Hz\n",
    "        window_size: Window size in seconds\n",
    "        window_step: Window step in seconds\n",
    "        \n",
    "    Returns:\n",
    "        Energy envelope (one value per frame)\n",
    "    \"\"\"\n",
    "    audio_signal = np.array(audio_signal)  # Ensure numpy array\n",
    "    \n",
    "    # Handle empty array\n",
    "    if len(audio_signal) == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "    # Ensure audio is 1D\n",
    "    if len(audio_signal.shape) > 1:\n",
    "        audio_signal = audio_signal.flatten()\n",
    "    \n",
    "    # Convert window sizes from seconds to samples\n",
    "    window_length = int(window_size * sample_rate)\n",
    "    hop_length = int(window_step * sample_rate)\n",
    "    \n",
    "    # Ensure valid window and hop lengths\n",
    "    window_length = max(window_length, 1)\n",
    "    hop_length = max(hop_length, 1)\n",
    "    \n",
    "    try:\n",
    "        # Compute RMS energy in each frame\n",
    "        energy = librosa.feature.rms(\n",
    "            y=audio_signal,\n",
    "            frame_length=window_length,\n",
    "            hop_length=hop_length\n",
    "        )[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting energy envelope: {e}\")\n",
    "        return np.array([])\n",
    "    \n",
    "    return energy\n",
    "\n",
    "def compute_envelope_features(envelope):\n",
    "    \"\"\"\n",
    "    Compute features from energy envelope.\n",
    "    \n",
    "    Args:\n",
    "        envelope: Energy envelope (one value per frame)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of envelope features\n",
    "    \"\"\"\n",
    "    envelope = np.array(envelope)  # Ensure numpy array\n",
    "    \n",
    "    # Handle empty array\n",
    "    if len(envelope) < 2:\n",
    "        return {\n",
    "            'mean_attack_rate': 0,\n",
    "            'mean_decay_rate': 0,\n",
    "            'attack_decay_ratio': 0,\n",
    "            'envelope_modulation': 0,\n",
    "            'attack_count': 0,\n",
    "            'decay_count': 0\n",
    "        }\n",
    "    \n",
    "    # Normalize envelope\n",
    "    if np.max(envelope) > np.min(envelope):\n",
    "        normalized = (envelope - np.min(envelope)) / (np.max(envelope) - np.min(envelope))\n",
    "    else:\n",
    "        normalized = np.zeros_like(envelope)\n",
    "    \n",
    "    # Compute attack and decay\n",
    "    attack_rates = []\n",
    "    decay_rates = []\n",
    "    \n",
    "    # Find regions of increasing energy (attacks) and decreasing energy (decays)\n",
    "    in_attack = False\n",
    "    in_decay = False\n",
    "    attack_start = 0\n",
    "    decay_start = 0\n",
    "    \n",
    "    for i in range(1, len(normalized)):\n",
    "        # Check for attack (significant increase)\n",
    "        if normalized[i] > normalized[i-1] + 0.05:\n",
    "            if not in_attack:\n",
    "                in_attack = True\n",
    "                attack_start = i - 1\n",
    "            in_decay = False\n",
    "        # Check for decay (significant decrease)\n",
    "        elif normalized[i] < normalized[i-1] - 0.05:\n",
    "            if in_attack:\n",
    "                # End of attack, calculate rate\n",
    "                attack_duration = i - attack_start\n",
    "                attack_magnitude = normalized[i-1] - normalized[attack_start]\n",
    "                if attack_duration > 0:\n",
    "                    attack_rates.append(attack_magnitude / attack_duration)\n",
    "                in_attack = False\n",
    "            \n",
    "            if not in_decay:\n",
    "                in_decay = True\n",
    "                decay_start = i - 1\n",
    "        # Check for end of decay\n",
    "        elif in_decay and (normalized[i] >= normalized[i-1] or i == len(normalized) - 1):\n",
    "            # End of decay, calculate rate\n",
    "            decay_duration = i - decay_start\n",
    "            decay_magnitude = normalized[decay_start] - normalized[i-1]\n",
    "            if decay_duration > 0:\n",
    "                decay_rates.append(decay_magnitude / decay_duration)\n",
    "            in_decay = False\n",
    "    \n",
    "    # Compute summary features\n",
    "    mean_attack_rate = np.mean(attack_rates) if attack_rates else 0\n",
    "    mean_decay_rate = np.mean(decay_rates) if decay_rates else 0\n",
    "    attack_decay_ratio = mean_attack_rate / mean_decay_rate if mean_decay_rate > 0 else 0\n",
    "    \n",
    "    # Compute envelope modulation\n",
    "    modulation = np.std(np.diff(normalized)) if len(normalized) > 1 else 0\n",
    "    \n",
    "    return {\n",
    "        'mean_attack_rate': mean_attack_rate,\n",
    "        'mean_decay_rate': mean_decay_rate,\n",
    "        'attack_decay_ratio': attack_decay_ratio,\n",
    "        'envelope_modulation': modulation,\n",
    "        'attack_count': len(attack_rates),\n",
    "        'decay_count': len(decay_rates)\n",
    "    }\n",
    "\n",
    "def extract_complete_trajectory_features(utterance, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Extract comprehensive trajectory-based features from a speech utterance.\n",
    "    \n",
    "    Args:\n",
    "        utterance: Audio samples\n",
    "        sample_rate: Sample rate in Hz\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of trajectory features\n",
    "    \"\"\"\n",
    "    utterance = np.array(utterance)  # Ensure numpy array\n",
    "    \n",
    "    # Handle empty utterance\n",
    "    if len(utterance) == 0:\n",
    "        return {'error': 'Empty utterance'}\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    try:\n",
    "        # Extract energy envelope\n",
    "        energy_envelope = extract_energy_envelope(utterance, sample_rate)\n",
    "        \n",
    "        # Skip if energy envelope extraction failed\n",
    "        if len(energy_envelope) == 0:\n",
    "            return {'error': 'Failed to extract energy envelope'}\n",
    "        \n",
    "        # Extract F0 contour (pitch) with error handling\n",
    "        try:\n",
    "            f0, voiced_flag, _ = librosa.pyin(\n",
    "                y=utterance,\n",
    "                fmin=librosa.note_to_hz('C2'),\n",
    "                fmax=librosa.note_to_hz('C7'),\n",
    "                sr=sample_rate,\n",
    "                frame_length=2048,\n",
    "                hop_length=512\n",
    "            )\n",
    "            # Replace NaN values with zeros for unvoiced frames\n",
    "            f0 = np.nan_to_num(f0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting pitch: {e}\")\n",
    "            f0 = np.zeros(len(energy_envelope))\n",
    "        \n",
    "        # 1. Linear trends\n",
    "        features['energy_trend'] = compute_linear_trend(energy_envelope)\n",
    "        features['f0_trend'] = compute_linear_trend(f0[f0 > 0]) if np.any(f0 > 0) else 0\n",
    "        \n",
    "        # 2. Dynamism features\n",
    "        features['energy_dynamism'] = compute_feature_dynamism(energy_envelope)\n",
    "        features['f0_dynamism'] = compute_feature_dynamism(f0[f0 > 0]) if np.any(f0 > 0) else 0\n",
    "        \n",
    "        # 3. Burst features\n",
    "        energy_burst_features = compute_burst_features(energy_envelope)\n",
    "        features.update({f'energy_{k}': v for k, v in energy_burst_features.items()})\n",
    "        \n",
    "        # 4. Peak analysis\n",
    "        energy_peak_features = analyze_peaks(energy_envelope)\n",
    "        features.update({f'energy_{k}': v for k, v in energy_peak_features.items()})\n",
    "        \n",
    "        # 5. Envelope features\n",
    "        envelope_features = compute_envelope_features(energy_envelope)\n",
    "        features.update(envelope_features)\n",
    "        \n",
    "        # 6. Combined joy-specific features\n",
    "        # Joy often has quick attacks, multiple peaks, and rising contours\n",
    "        features['joy_signature'] = (\n",
    "            0.3 * features['energy_trend'] +\n",
    "            0.2 * features.get('energy_burst_count', 0) +\n",
    "            0.2 * features['mean_attack_rate'] +\n",
    "            0.15 * features.get('energy_peak_count', 0) +\n",
    "            0.15 * features['energy_dynamism']\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting trajectory features: {e}\")\n",
    "        return {'error': str(e)}\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'energy_trend': -0.2875793509098498,\n",
       " 'f0_trend': -0.9611192665245489,\n",
       " 'energy_dynamism': 0.0634389516097663,\n",
       " 'f0_dynamism': 0.0797550393203035,\n",
       " 'energy_burst_count': 6,\n",
       " 'energy_burst_rate': 0.021739130434782608,\n",
       " 'energy_mean_burst_magnitude': 1.7978616,\n",
       " 'energy_max_burst_magnitude': 1.9350402,\n",
       " 'energy_burst_coverage': 0.12681159420289856,\n",
       " 'energy_first_burst_position': 0.12681159420289856,\n",
       " 'energy_peak_count': 13,\n",
       " 'energy_peak_rate': 0.04710144927536232,\n",
       " 'energy_mean_peak_prominence': 0.5085252295729543,\n",
       " 'energy_max_peak_prominence': 0.9999764898529975,\n",
       " 'energy_peak_position_mean': 0.4512263099219621,\n",
       " 'energy_peak_position_std': 0.205143730327128,\n",
       " 'energy_peak_width_mean': 0.0,\n",
       " 'mean_attack_rate': 0.06825807407802464,\n",
       " 'mean_decay_rate': 0.04757227784952784,\n",
       " 'attack_decay_ratio': 1.43482879449091,\n",
       " 'envelope_modulation': 0.080516785,\n",
       " 'attack_count': 14,\n",
       " 'decay_count': 11,\n",
       " 'joy_signature': 3.086893652284115}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_complete_trajectory_features(enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
